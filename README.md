# ğŸ§  SNNGesturesPortentaH7

Spiking Neural Network (SNN) for real-time gesture recognition using the **Arduino Portenta H7** and an **OV7670 camera**. This project implements biologically-inspired neural computing on edge hardware using radially invariant Fourier features extracted from video frames.

---

## ğŸ“¦ Project Structure

```
SNNGesturesPortentaH7/
â”œâ”€â”€ portenta/              # Arduino sketch & SNN logic
â”‚   â”œâ”€â”€ portentacam.ino
â”‚   â”œâ”€â”€ weights.h
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/               # Python utilities for training and inference
â”‚   â”œâ”€â”€ cameraread2.py     # Live camera inference from host side
â”‚   â”œâ”€â”€ pbtalgo.py         # Population-Based Training algorithm
â”‚   â”œâ”€â”€ prepweights.py     # Converts weights to C-style header
â”‚   â”œâ”€â”€ videotoimage.py    # Splits videos into training images
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                # Pretrained or trained weights
â”‚   â”œâ”€â”€ w1_64.csv
â”‚   â””â”€â”€ w2_64.csv
â”œâ”€â”€ data/                  # Gesture image datasets
â”‚   â”œâ”€â”€ gesture0/
â”‚   â”œâ”€â”€ gesture0_test/
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

---

## ğŸ“· Hardware Requirements

- **Arduino Portenta H7**
  - STM32H747XI dual-core (M7 + M4)
  - 8 MB SDRAM / 16 MB Flash
  - MIPI DSI, DVP camera interface
- **OV7670 Camera Module**
  - VGA (640Ã—480), used in QVGA (320Ã—240)
  - RGB565 format at 30 FPS
- **Portenta Breakout Board**
  - Enables GPIO clock generation via HAL (for XCLK)
  - Uses 80-pin high-density connectors

---

## âš™ï¸ Setup Instructions

### Arduino Side

1. **Install Arduino IDE**:  
   https://www.arduino.cc/en/software

2. **Install Required Libraries**:
   - `Mbed OS`
   - `Arducam_dvp.h`
   - `Arduino_PortentaBreakout.h`

3. **Flash Arduino Code**:
   - Open and upload `portentacam.ino` to your Portenta.
   - Ensure `weights.h` matches your network size.

---

### Python Side (Host System)

#### ğŸ”§ Environment

Install [Miniconda](https://www.anaconda.com/download) and then:

```bash
pip install opencv-python numpy matplotlib numba pyserial mediapipe==0.10.13
```

#### ğŸ¥ Live Inference

```bash
python cameraread2.py --inc 0.078 --leak 0.01 --amp-mid 1.3
```

Optional flags:
- `--video-only` : Record raw camera input for new data
- `--alpha`, `--beta` : Adjust contrast/brightness

---

## ğŸ“Š Training New Gestures

1. **Record gesture videos**:
   ```bash
   python cameraread2.py --video-only
   ```

2. **Extract and normalize frames**:
   ```bash
   python videotoimage.py --start-index 0 myvideo.mp4 ./data/gesture1
   ```

3. **Train your model**:
   ```bash
   python pbtalgo.py --w1-file w1_64.csv --w2-file w2_64.csv --steps 100
   ```

4. **Convert weights to C header**:
   ```bash
   python prepweights.py
   ```

5. **Move new `weights.h` to Arduino project** and re-flash.

---

## ğŸ§  SNN Details

- Radially Invariant Fourier Transform (RIFT) for input encoding
- LIF neuron dynamics:
  - `increment`, `leak_ratio`, `threshold`, etc.
- STDP with target firing rates (`target_true`, `target_false`)
- Uses **Population-Based Training** (PBT) to select optimal weights
- Temporal processing over `steps` (e.g., 100 time steps per gesture)

---

## ğŸ›  Example Parameters

| Parameter        | Value   | Description                                 |
|------------------|---------|---------------------------------------------|
| `n_hidden`       | 64      | Number of hidden neurons (and input bins)   |
| `n_output`       | 16      | Number of output neurons                    |
| `neurons_per_group` | 8   | Output neurons per label (2 labels here)    |
| `eta_w2`         | 0.0001  | STDP learning rate                          |
| `target_true`    | 200     | Desired spikes for correct label            |
| `punish_factor`  | 35      | Penalty scale for incorrect spikes          |
| `epochs`         | 500     | Number of training epochs                   |

---

## ğŸ“ Useful Links

- ğŸ”— [Arduino IDE Download](https://www.arduino.cc/en/software)
- ğŸ”— [Miniconda (Recommended)](https://www.anaconda.com/download)
- ğŸ”— [Project Repository](https://github.com/INQUIRELAB/SNNGesturesPortentaH7)

---

## ğŸ“Œ License

This project is open-source and distributed under the MIT License.
